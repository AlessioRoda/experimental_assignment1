# Cluedo simulation for the Experimental Robotics Lab course, Alessio Roda S4458313

The purpose of this repository is to generate a simulation for the Cluedo game, in which the robot moves from a room to another in the Gazebo simulation, searches for ArUco markers that provide the hints to determine who is the murder and tries to provide a solution basing on the collected hints, until the correct solution is found. The scenario in which the robot moves is composed by six different rooms in which there are five ArUco markers; the robot is able to move in the environment mapping it with the laser_scan that is mounted on its basis in order to generate a global map of the area. Also, the robot has a manipulator in which is mounted a camera on the end effector that is needed to detect the markers: the robot continuously moves the arm in order to visualize all the markers in the room, since they are in not defined position and orientations.


## Description of the architecture

![cluedo](https://user-images.githubusercontent.com/48511957/142238407-b648df07-2806-474c-a22e-d787d1638970.jpg)

The architecture is divided into four packages:
* aruco_ros: the package already provided to recognize the ArUco markers from the camera images
* erl2: the main package of the architecture: it provides the FSM that manages the behavior of the robot, the node to interface with the ARMOR ontology and the node to perform the movement of the robotic arm needed to detect the markers
* exp_assignment3: package already provided for the simulation
* moveit_config: the package generated with the Moveit setup assistant for generating all the packages that allow to control the motion of the arm

Concerning the aruco_ros and moveit_config packages only small modifications have been done: for the first one a publisher of the marker ID has been added inside aruco_ros/aruco_ros/marker_publish.cpp, instead in the second one some small changes were needed to change the default Gazebo simulation environment, generated by the setup assistant, to the new simulation environment provided for the Cluedo game.

Inside the erl2 folder you can find:
* config folder containing the configuration files for the Rviz simulation and the motor controllers
* docs folder with the sphinx code documentation
* launch folder in which there are the launch files for running all the nodes of the simulation
* msg folder containing the ErlOracle.msg for defining the hint message generated by the final_oracle node in the exp_assignment3 folder
* param folder containing all the parameters required for the SLAM gmapping
* scripts folder containing the ontology_interface.py script to manage the queries for the ARMOR ontology and the state_machine.py script to manage the SMACH state machine that represents the behavior of the robot during the simulation. It als contains a sub folder with the MyArmor and Place classes.
* src folder with the movearm.cpp file that provides the node that manages the motion of the robotic arm
* srv folder with all the service custom messages
* urdf folder with the robot.urdf description file for the simulation
* world folder containing the world description of the simulation
* cluedo_ontology.owl that describes the initial ontology
* launch_simulation.sh for launching all the launch files simultaneously

The exp_assignment3 package has't been modified 

### Component diagram![UML_diagram_1](https://user-images.githubusercontent.com/48511957/192112566-e148c48a-2451-4152-b598-c8555e20262d.png)

Here is provided the component diagram to better explain how the architecture works. As it's possible to notice, the state_machine node is the "heart" of the entire architecture, in particular:
* It initializes Place objects to define the rooms (name, x, y) 
* Manages the motion of the robot by sending a MoveBase action goal with the coordinates of the room to reach when the simulation is in the MOVE state
* Receives all the maker ids that are detected by the aruco_ros node via /marker_id service, it saves and send them to the final oracle node, so to receive as a response the cluedo hint
* During the CHECK_CONSISTENCY state it sends the hints to the ontology_interface via /ontology_interface/add_hint service 
* Asks for updating the ontology via /ontology_interface/update_request service
* Asks all the complete and consistent hypothesis in the ontology sending the /ontology_interface/check_consistency service and receives as service Response the list containing the IDs of all the complete and consistent hypothesis
* It asks the cluedo solution ID to the final_oracle node by sending the /oracle_solution request and compares the service response that receives with all the complete and consistent IDs that have received before. If one of them is the solution of the cluedo game, the simulation ends, otherwise it continues

The ontology_interface node receives the previously described services to interact with the ARMOR ROS service to manage the ontology, in particular:
* It initializes the ontology by adding all the places, weapons and people of the game
* When the /ontology_interface/add_hint request is received, it stores the hints in three different lists 
* When /ontology_interface/update_request service request is received it adds the hints to the ontology and update it with the REASON armor command
* When /ontology_interface/check_consistency service request is received it uses the armor commands to query all the complete and consistent hypothesis IDs of the ontology and returns them as service response 
* When /ontology_interface/ask_solution service request is received, it uses armor commands to query the person, the weapon and the place of the cluedo game given the solution ID provides in the request

All the armor operations are performed by calling the MyArmor class, a custom class that provides a morea agile way to send armor messages (for more information about, please have a look at the sphinx documentation)

The moevearm ros node does't communicate with the rest of the architecture, it just moves the robotic arm in four different positions already defined with the moveit_setup_assistant. It allows the arm to continuously move in an infinite loop, that allows to better investigate the environment in order to detect the markers

Finally, regarding the aruco_ros component and the final_oracle node everything was already provided, except for the publisher to the /marker_id topic that allows the aruco_ros component to send the ID corresponding to the aruco marker that has been detected by the camera.

To manage the motion of the robot from a room to another, the robot creates a map of the environment with the laser_scan and the gmapping module (here you can find more information about http://wiki.ros.org/gmapping) and generates a path to follow with the navigation module (http://wiki.ros.org/navigation). 

Here you can find also the rqt_graph generated by ROS to have another nice representation about how the different nodes communicate between eachother.
![rosgraph](https://user-images.githubusercontent.com/48511957/191740042-d38bdb64-4807-4aa2-87bf-9d1e83e048de.png)

## SMACH FSM

![smach](https://user-images.githubusercontent.com/48511957/192152132-9fc66550-da8b-42eb-8cde-c38433b1d203.PNG)
 The simulation starts in the EXPLORE state, here a MoveBase goal is sent with the coordinates of one of the rooms in the environment that haven't been already visited or, in case the flag variable to determine if the robot must go in the oracle room or not, it moves to the oracle room. The state waits until the action is completed, then it will wait five seconds to let the arm explore the area with the camera searching the markers. After that, the FSM goes in the CHECK_CONSISTENCY state, in which it sends a service message on topic /oracle_hint for each marker ID that has been collected until that moment and adds the corresponding hints in the ontology. Then it asks for all the complete and consistent hypothesis in the ontology and in case there are any, it updates a flag to go in the oracle room, then returns in the EXPLORE state.
Finally, when robot reaches the oracle room, it enters in the TRY_SOLUTION state and checks if one of the possible solutions that have found is the real oracle solution to the cluedo game; in case it is the game ends and the FSM returns 'correct', otherwise it returns in the EXPLORE state.


## How to run the code
This project was developed and tested on Ubuntu 20.04 with ROS noetic, in order to install all the necessary dependencies make sure you have installed in your system:

* smach
* move_base
* gmapping
* navigation
* moveit
* ARMOR (here the link https://github.com/EmaroLab/armor)

After that, clone the repository in your ros workspace, enter in it and move to the third_assignment branch with the git command 

```
git checkout third_assignment
```
compile the repository with 

```
catkin_make
```
Then the best way to run the code is to go inside erl2 folder, then launch the simulation by running in your terminal

```
./launch_simulation.sh
```

### Run the nodes separately

If you want to have a view of all the nodes that are running with all the logs that they print, you can run them separately; in order to do so, pleas follow the commands above

```
roslaunch erl2 simulation.launch
```
```
rosrun armor execute it.emarolab.armor.ARMORMainService
```
```
roslaunch erl2 gmapping.launch
```
```
rosrun aruco_ros marker_publisher
```
```
rosrun exp_assignment3 final_oracle
```
```
rosrun erl2 ontology_interface.py _ontology:=(your_ros_workspace)/exp_assignment1/erl2/cluedo_ontology.owl
```
```
rosrun erl2 state_machine.py
```
```
rosrun erl2 movearm
```

You should see the Gazebo and Rviz simulation running, for the Rviz one you should manually add the robot model, the map, the camera and the navigation plan to see everything properly.

## Simulation recording
Here you can find the video recording about the whole simulation (). Above there are some screenshots from the gazebo and Rviz simulation.

## System features and limitations
The code was tested either on a native Ubuntu 20.04 distribution and on a Docker image running on Windows 10. It's important to notice that, since the mapping of the area requires a good level of computational power, in the native Docker distribution the creation of the map may generate some "errors", like detecting obstacles that aren't in fact in the simulation, while it doesn't happen on the native Ubuntu distribution. Also, in the Docker image the robot is slower and the simulation may require more time to finish. Anyway, the resulting performance of the systems are considered reasonably fine in both the environments. Another limitation that has been encountered during the tests is that the ontology_interface node sometimes cold not upload correctly the people, the weapons and the places of the ontology, since the armor nodes returns an error; closing the terminal with the ontology_interface node and running it again, all the elements are uploaded correctly and the "Ontology loaded successfully" log appears on the terminal. 
Regarding the possible future improvements, in order to make the simulation faster on the Docker image, the gmapping parameters in the param folder can be changed. Also, the ontology_interface node doesn't remove the complete and consistent hypothesis from the ontology once it's discovered that they don't represent the oracle solution, in case of much more markers and possible hints to add to the simulation this could be an important improvement to reduce the time to search the elements in the ontology. Even more a possible solution to the problem in uploading the ontology in the ontology_interface node could consist in waiting some time and trying to upload it again.

## Author information and contacts
I'm Alessio Roda, I'm a robotics engineering student in the University of Genoa, if you have some issues you can contact me via mail: alessioroda98@gmail.com.



